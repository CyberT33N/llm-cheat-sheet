# LLM cheat sheet

<br><br>

## Guides
- https://www.youtube.com/watch?v=zjkBMFhNj_g

<br><br>

# Structure
- E.g. llama-2-70b
  - Contains 2 files

    - **parameters**: Weights of the neural network 
      - 140GB big because 70b of the LLM is stored in 2 bytes (float16)

	- **run**: Lines of c code to run the LLM
	  - Can be in any programming language


<br><br>

# Training
- You can understand that you will collect informations as text from websites in a big amount like e.g. 10TB
  -> Train with 6000 GPUS for 12 days (2$ million dollar)
    -> Compress the information to parameters.zip (140GB) 
      - Not really a .zip doe but easier to understand


<br><br>

# Neural network
- aka next work prediction neural network
  - E.g. you give the sentence `cat sat on a` as sequence then it will predicts the next word (mat 97%).
	- There is mathematically relationship between prediction and compression. So this is why we called it compression in the section training. Because if you can predict the nord word you can compress the dataset.

<br><br>

## LLM dreams
- So when a neural network will predict the next word you can think of web page dreaming because the neural network was trained with web pages. E.g. if you have an amazon product page then ISBN: 2324342424242 would look this this.
  - So if the ISBN number was generated by the LLM then it will not exists but it will know the length and format because it was trained with data like this.
  - The same dreaming logic goes for code or blog articles
    - **This is the reason why you often get falsy informations when you ask questions because the LLM just predicts what it thinks will be right for the next sequence**

























<br><br>
<br><br>
___________________________________________
___________________________________________
<br><br>
<br><br>


## Traing Steps

<br><br>

## Stage 1 - Pre Training base model - Knowledge Stage
- The first step of training will be using document sample from around the internet. E.g. code blocks or product page. The quality is not high because it is scraped data without any review. So it is **quanity > quality**

- Because of the price it will be roughly done every years
```
1. Download ~10TB of text
2. Get a cluster of ~6000 GPUS
3. Compress the text into a neural network, pay ~$2M, wait ~12 days
4. Obtain base model
```

<br><br>

## Stage 2 - Fine Tuning asisstent model  - Assistent Model - Alignment Stage
- The second step is by training with example of real questions and answer datasets too prepare the neural network for questions that it can actually act as assistant.
  - The documents with real questions and answers were written by real humand which companies were hiring to get the most accurate result.
    - The quality is high because it is esspecially written from real humans for the fine tuning. So it is **quality > quanity**

- If you would ask now a questions after the fine tuning the llm will now detect that you asked a questions and will try to response with an answer even when the questions was not in the dataset of the finetuning.

- **You can aslo see this traing step as changing the format from internet documents -> question & answer documents**

- Because this stage of far cheaper than stage 1 this will be done like every week to improve the model and fix misbehaviors
```
1. Writing labeling instructions
2. Hire people (or use scale.ai), collect 100K high quality ideal Q&A responsed and/or comparisons
3. Finetune base model on this data, wait ~1 day
4. Obtain assistant model
5. Run a lot of evaluations
6. Deploy
7. Monitor, collect misbehaviors, go to step 1
  - misbehaviors will be manually solved by real humans so the wrong answer will be overwritten
    - So if you run the fine tuning again the model will improve in this case
```

<br><br>

## Stage 3 (optional) - Comparsion
- It is often much easiert to compare Answers instead of writing Answers
  - This means you could ask the assistant model a questions and then re-ask the question a few time and then pick the best result.

<br><br>

## Nice 2 know
- Meta has released the base model aswell so if you want you can fine tune the model by yourself














<br><br>
<br><br>

## Labeling Instructions
- These instruction documents can grow to hundreds of page and can be very complicated. In fact they contains the restrictions of behaviour how the lLM should act in order to avoid harmful or unethatical responses
  - You may think that those labeling instructions are fully human solved/written but in the past when LLM increased there is more like an human & machine collaboration.
    - This means you can let the LLM give you answers and then you as human cherry pick the best answers. Or you can ask the LLM to check your work or ask them to create comparsions
      - So over the next years when the LLM will get better and better there will be less manually scratch work by humans instead we work more with the LLM










































<br><br>
<br><br>
___________________________________________
___________________________________________
<br><br>
<br><br>

## Chatbot arena leaderboard
- https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard

- You can understand the elo rating as an comparsion of the battle between LLM. Like e.g. if humans would play chess against each other and you determine the best player
  - So you would ask questions to 2 LLM and then decide which LLM give the better or more correct answer

- The leaderboard top LLM are mostly from big companies where the weights are not open source. However, because the base model of LLAMA is opensource a lot of companies are fine tuning there own models based on the base model.
